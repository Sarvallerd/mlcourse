{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\">\n    \n## [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \nAuthor: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose.","metadata":{"_uuid":"3f6c2bfe6b2e26c92357e896a1511195d836956e"}},{"cell_type":"markdown","source":"## <center> Assignment 4. Sarcasm detection with logistic regression\n    \nWe'll be using the dataset from the [paper](https://arxiv.org/abs/1704.05579) \"A Large Self-Annotated Corpus for Sarcasm\" with >1mln comments from Reddit, labeled as either sarcastic or not. A processed version can be found on Kaggle in a form of a [Kaggle Dataset](https://www.kaggle.com/danofer/sarcasm).\n\nSarcasm detection is easy. \n<img src=\"https://habrastorage.org/webt/1f/0d/ta/1f0dtavsd14ncf17gbsy1cvoga4.jpeg\" />","metadata":{"_uuid":"cb01ca96934e5c83a36a2308da9645b87a9c52a0"}},{"cell_type":"code","source":"!ls ../input/sarcasm/","metadata":{"_uuid":"23a833b42b3c214b5191dfdc2482f2f901118247","execution":{"iopub.status.busy":"2023-04-15T09:13:00.926947Z","iopub.execute_input":"2023-04-15T09:13:00.927589Z","iopub.status.idle":"2023-04-15T09:13:02.044108Z","shell.execute_reply.started":"2023-04-15T09:13:00.927533Z","shell.execute_reply":"2023-04-15T09:13:02.042820Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"test-balanced.csv    train-balanced-sarc.csv.gz\ntest-unbalanced.csv  train-balanced-sarcasm.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# some necessary imports\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport seaborn as sns\nfrom matplotlib import pyplot as plt","metadata":{"_uuid":"ffa03aec57ab6150f9bec0fa56cd3a5791a3e6f4","execution":{"iopub.status.busy":"2023-04-15T09:21:36.383631Z","iopub.execute_input":"2023-04-15T09:21:36.384010Z","iopub.status.idle":"2023-04-15T09:21:36.389811Z","shell.execute_reply.started":"2023-04-15T09:21:36.383945Z","shell.execute_reply":"2023-04-15T09:21:36.388745Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/sarcasm/train-balanced-sarcasm.csv')","metadata":{"_uuid":"b23e4fc7a1973d60e0c6da8bd60f3d921542a856","execution":{"iopub.status.busy":"2023-04-15T09:13:21.098730Z","iopub.execute_input":"2023-04-15T09:13:21.099273Z","iopub.status.idle":"2023-04-15T09:13:31.737927Z","shell.execute_reply.started":"2023-04-15T09:13:21.099181Z","shell.execute_reply":"2023-04-15T09:13:31.736954Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"_uuid":"4dc7b3787afa46c7eb0d0e33b0c41ab9821c4a27","execution":{"iopub.status.busy":"2023-04-15T09:13:31.739251Z","iopub.execute_input":"2023-04-15T09:13:31.739532Z","iopub.status.idle":"2023-04-15T09:13:31.790501Z","shell.execute_reply.started":"2023-04-15T09:13:31.739484Z","shell.execute_reply":"2023-04-15T09:13:31.789188Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   label                        ...                                                             parent_comment\n0      0                        ...                          Yeah, I get that argument. At this point, I'd ...\n1      0                        ...                          The blazers and Mavericks (The wests 5 and 6 s...\n2      0                        ...                                                    They're favored to win.\n3      0                        ...                                                 deadass don't kill my buzz\n4      0                        ...                          Yep can confirm I saw the tool they use for th...\n\n[5 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>comment</th>\n      <th>author</th>\n      <th>subreddit</th>\n      <th>score</th>\n      <th>ups</th>\n      <th>downs</th>\n      <th>date</th>\n      <th>created_utc</th>\n      <th>parent_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NC and NH.</td>\n      <td>Trumpbart</td>\n      <td>politics</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-16 23:55:23</td>\n      <td>Yeah, I get that argument. At this point, I'd ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>You do know west teams play against west teams...</td>\n      <td>Shbshb906</td>\n      <td>nba</td>\n      <td>-4</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-11</td>\n      <td>2016-11-01 00:24:10</td>\n      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>They were underdogs earlier today, but since G...</td>\n      <td>Creepeth</td>\n      <td>nfl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2016-09</td>\n      <td>2016-09-22 21:45:37</td>\n      <td>They're favored to win.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>This meme isn't funny none of the \"new york ni...</td>\n      <td>icebrotha</td>\n      <td>BlackPeopleTwitter</td>\n      <td>-8</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-18 21:03:47</td>\n      <td>deadass don't kill my buzz</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>I could use one of those tools.</td>\n      <td>cush2push</td>\n      <td>MaddenUltimateTeam</td>\n      <td>6</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-12</td>\n      <td>2016-12-30 17:00:13</td>\n      <td>Yep can confirm I saw the tool they use for th...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.info()","metadata":{"_uuid":"0a7ed9557943806c6813ad59c3d5ebdb403ffd78","execution":{"iopub.status.busy":"2023-04-15T09:13:31.792156Z","iopub.execute_input":"2023-04-15T09:13:31.792544Z","iopub.status.idle":"2023-04-15T09:13:32.327307Z","shell.execute_reply.started":"2023-04-15T09:13:31.792468Z","shell.execute_reply":"2023-04-15T09:13:32.326298Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1010826 entries, 0 to 1010825\nData columns (total 10 columns):\nlabel             1010826 non-null int64\ncomment           1010773 non-null object\nauthor            1010826 non-null object\nsubreddit         1010826 non-null object\nscore             1010826 non-null int64\nups               1010826 non-null int64\ndowns             1010826 non-null int64\ndate              1010826 non-null object\ncreated_utc       1010826 non-null object\nparent_comment    1010826 non-null object\ndtypes: int64(4), object(6)\nmemory usage: 77.1+ MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Some comments are missing, so we drop the corresponding rows.","metadata":{"_uuid":"6472f52fb5ecb8bb2a6e3b292678a2042fcfe34c"}},{"cell_type":"code","source":"train_df.dropna(subset=['comment'], inplace=True)","metadata":{"_uuid":"97b2d85627fcde52a506dbdd55d4d6e4c87d3f08","execution":{"iopub.status.busy":"2023-04-15T09:13:48.216300Z","iopub.execute_input":"2023-04-15T09:13:48.217033Z","iopub.status.idle":"2023-04-15T09:13:48.530266Z","shell.execute_reply.started":"2023-04-15T09:13:48.216947Z","shell.execute_reply":"2023-04-15T09:13:48.529096Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"We notice that the dataset is indeed balanced","metadata":{"_uuid":"9d51637ee70dca7693737ad0da1dbb8c6ce9230b"}},{"cell_type":"code","source":"train_df['label'].value_counts()","metadata":{"_uuid":"addd77c640423d30fd146c8d3a012d3c14481e11","execution":{"iopub.status.busy":"2023-04-15T09:13:49.420375Z","iopub.execute_input":"2023-04-15T09:13:49.420699Z","iopub.status.idle":"2023-04-15T09:13:49.442307Z","shell.execute_reply.started":"2023-04-15T09:13:49.420644Z","shell.execute_reply":"2023-04-15T09:13:49.441461Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0    505405\n1    505368\nName: label, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"We split data into training and validation parts.","metadata":{"_uuid":"5b836574e5093c5eb2e9063fefe1c8d198dcba79"}},{"cell_type":"code","source":"train_texts, valid_texts, y_train, y_valid = \\\n        train_test_split(train_df['comment'], train_df['label'], random_state=17)","metadata":{"_uuid":"c200add4e1dcbaa75164bbcc73b9c12ecb863c96","execution":{"iopub.status.busy":"2023-04-15T09:13:50.542168Z","iopub.execute_input":"2023-04-15T09:13:50.542538Z","iopub.status.idle":"2023-04-15T09:13:50.780540Z","shell.execute_reply.started":"2023-04-15T09:13:50.542484Z","shell.execute_reply":"2023-04-15T09:13:50.779568Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Tasks:\n1. Analyze the dataset, make some plots. This [Kernel](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc) might serve as an example\n2. Build a Tf-Idf + logistic regression pipeline to predict sarcasm (`label`) based on the text of a comment on Reddit (`comment`).\n3. Plot the words/bigrams which a most predictive of sarcasm (you can use [eli5](https://github.com/TeamHG-Memex/eli5) for that)\n4. (optionally) add subreddits as new features to improve model performance. Apply here the Bag of Words approach, i.e. treat each subreddit as a new feature.\n\n## Links:\n  - Machine learning library [Scikit-learn](https://scikit-learn.org/stable/index.html) (a.k.a. sklearn)\n  - Kernels on [logistic regression](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification) and its applications to [text classification](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit), also a [Kernel](https://www.kaggle.com/kashnitsky/topic-6-feature-engineering-and-feature-selection) on feature engineering and feature selection\n  - [Kaggle Kernel](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle) \"Approaching (Almost) Any NLP Problem on Kaggle\"\n  - [ELI5](https://github.com/TeamHG-Memex/eli5) to explain model predictions","metadata":{"_uuid":"7f0f47b98e49a185cd5cffe19fcbe28409bf00c0"}},{"cell_type":"code","source":"vec = TfidfVectorizer()\nclf = LogisticRegressionCV()\npipeline = Pipeline([('vec', vec), ('clf', clf)])\npipeline.fit(train_texts, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T09:21:39.097347Z","iopub.execute_input":"2023-04-15T09:21:39.098077Z","iopub.status.idle":"2023-04-15T09:29:15.671562Z","shell.execute_reply.started":"2023-04-15T09:21:39.098011Z","shell.execute_reply":"2023-04-15T09:29:15.670396Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Pipeline(memory=None,\n     steps=[('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n ...    random_state=None, refit=True, scoring=None, solver='lbfgs',\n           tol=0.0001, verbose=0))])"},"metadata":{}}]},{"cell_type":"code","source":"import eli5\nfrom eli5 import explain_weights, explain_prediction\nfrom eli5.formatters import format_as_html, format_as_text, format_html_styles, fields\nfrom IPython.core.display import display, HTML\n\nshow_html = lambda html: display(HTML(html))\nshow_html_expl = lambda expl, **kwargs: show_html(format_as_html(expl, include_styles=False, **kwargs))\nshow_html(format_html_styles())","metadata":{"execution":{"iopub.status.busy":"2023-04-15T09:32:25.849859Z","iopub.execute_input":"2023-04-15T09:32:25.850404Z","iopub.status.idle":"2023-04-15T09:32:26.258144Z","shell.execute_reply.started":"2023-04-15T09:32:25.850314Z","shell.execute_reply":"2023-04-15T09:32:26.257330Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.eli5-weights tr:hover {\n        filter: brightness(85%);\n    }\n</style>"},"metadata":{}}]},{"cell_type":"code","source":"eli5.show_weights(clf, vec=vec, target_names=train_texts, horizontal_layout=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T09:32:52.322281Z","iopub.execute_input":"2023-04-15T09:32:52.322688Z","iopub.status.idle":"2023-04-15T09:32:52.570588Z","shell.execute_reply.started":"2023-04-15T09:32:52.322600Z","shell.execute_reply":"2023-04-15T09:32:52.569235Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    table.eli5-weights tr:hover {\n        filter: brightness(85%);\n    }\n</style>\n\n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n        \n\n    \n\n        \n            \n                \n                \n    \n        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n            <b>\n    \n        y=1\n    \n</b>\n\ntop features\n        </p>\n    \n    <table class=\"eli5-weights\"\n           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n        <thead>\n        <tr style=\"border: none;\">\n            \n                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n                    Weight<sup>?</sup>\n                </th>\n            \n            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n            \n        </tr>\n        </thead>\n        <tbody>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +6.723\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        obviously\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 81.46%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +6.031\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        clearly\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 82.24%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +5.675\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        totally\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 83.34%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +5.177\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        forgot\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 83.79%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +4.979\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        dropped\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 84.51%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +4.667\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        yeah\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 84.52%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +4.663\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        because\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 84.81%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +4.536\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        duh\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 84.98%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +4.467\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        dare\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 86.35%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +3.894\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        gee\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 86.48%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +3.842\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        shitlord\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 86.89%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +3.678\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        amirite\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 87.08%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +3.603\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        fault\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 87.09%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +3.597\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        racist\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 87.13%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +3.580\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        must\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 87.40%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +3.475\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        therefore\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 87.65%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +3.375\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        sexist\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 87.69%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +3.363\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        shocked\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 87.72%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +3.349\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        scrub\n    </td>\n    \n</tr>\n        \n        \n            <tr style=\"background-color: hsl(120, 100.00%, 87.72%); border: none;\">\n                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n                    <i>&hellip; 65844 more positive &hellip;</i>\n                </td>\n            </tr>\n        \n\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 87.05%); border: none;\">\n                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n                    <i>&hellip; 77443 more negative &hellip;</i>\n                </td>\n            </tr>\n        \n        \n            <tr style=\"background-color: hsl(0, 100.00%, 87.05%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -3.613\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        iirc\n    </td>\n    \n</tr>\n        \n\n        </tbody>\n    </table>\n\n            \n        \n\n        \n\n\n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n\n"},"metadata":{}}]},{"cell_type":"code","source":"show_html_expl(\n    explain_prediction(clf, valid_texts.reset_index(drop=True)[1], vec, target_names=train_texts),\n    force_weights=False, horizontal_layout=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T09:36:41.657615Z","iopub.execute_input":"2023-04-15T09:36:41.657970Z","iopub.status.idle":"2023-04-15T09:36:41.919959Z","shell.execute_reply.started":"2023-04-15T09:36:41.657919Z","shell.execute_reply":"2023-04-15T09:36:41.918313Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n\n\n    \n        <p>Explained as: linear model</p>\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n        \n\n    \n\n        \n\n        \n    \n        \n        \n    \n        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n            <b>\n    \n        y=1\n    \n</b>\n\n    \n    (probability <b>0.545</b>, score <b>0.181</b>)\n\ntop features\n        </p>\n    \n    <table class=\"eli5-weights\"\n           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n        <thead>\n        <tr style=\"border: none;\">\n            \n                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n                    Contribution<sup>?</sup>\n                </th>\n            \n            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n            \n        </tr>\n        </thead>\n        <tbody>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.720\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        Highlighted in text (sum)\n    </td>\n    \n</tr>\n        \n        \n\n        \n        \n            <tr style=\"background-color: hsl(0, 100.00%, 83.66%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.539\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        &lt;BIAS&gt;\n    </td>\n    \n</tr>\n        \n\n        </tbody>\n    </table>\n\n    \n\n\n\n    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n        <span style=\"background-color: hsl(0, 100.00%, 95.24%); opacity: 0.81\" title=\"-0.016\">it</span><span style=\"opacity: 0.80\">&#x27;s </span><span style=\"background-color: hsl(0, 100.00%, 95.95%); opacity: 0.81\" title=\"-0.013\">like</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.72%); opacity: 0.80\" title=\"0.002\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.15%); opacity: 0.81\" title=\"0.017\">label</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.49%); opacity: 0.89\" title=\"-0.149\">actually</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.06%); opacity: 0.82\" title=\"0.040\">has</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.75%); opacity: 0.83\" title=\"0.055\">no</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.63%); opacity: 0.88\" title=\"-0.139\">meaning</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.22%); opacity: 0.86\" title=\"-0.107\">beyond</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.69%); opacity: 0.88\" title=\"-0.129\">some</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.05%); opacity: 0.81\" title=\"-0.012\">kindergarten</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 79.54%); opacity: 0.88\" title=\"0.130\">tier</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.08%); opacity: 0.81\" title=\"0.017\">tactics</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.80%); opacity: 0.81\" title=\"0.009\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.45%); opacity: 0.86\" title=\"0.096\">belittle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 62.12%); opacity: 0.99\" title=\"0.314\">women</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.19%); opacity: 0.80\" title=\"-0.001\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.13%); opacity: 0.82\" title=\"0.039\">being</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.46%); opacity: 0.90\" title=\"-0.169\">interested</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.72%); opacity: 0.83\" title=\"-0.049\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.53%); opacity: 0.80\" title=\"0.001\">things</span><span style=\"opacity: 0.80\">, (</span><span style=\"background-color: hsl(0, 100.00%, 93.39%); opacity: 0.82\" title=\"-0.026\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.78%); opacity: 0.81\" title=\"-0.009\">then</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.45%); opacity: 0.84\" title=\"-0.065\">whine</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.02%); opacity: 0.82\" title=\"-0.040\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.49%); opacity: 0.80\" title=\"0.007\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.32%); opacity: 0.80\" title=\"0.007\">lack</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.10%); opacity: 0.81\" title=\"-0.022\">of</span><span style=\"opacity: 0.80\"> &quot;</span><span style=\"background-color: hsl(120, 100.00%, 76.42%); opacity: 0.89\" title=\"0.160\">real</span><span style=\"opacity: 0.80\">&quot; </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.340\">nerd</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.17%); opacity: 0.91\" title=\"0.182\">girls</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.54%); opacity: 0.81\" title=\"-0.020\">afterwards</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(0, 100.00%, 93.39%); opacity: 0.82\" title=\"-0.026\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.72%); opacity: 0.80\" title=\"0.002\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.64%); opacity: 0.88\" title=\"0.129\">everything</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.49%); opacity: 0.80\" title=\"0.007\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.39%); opacity: 0.86\" title=\"0.097\">counter</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 95.48%); opacity: 0.81\" title=\"-0.015\">movement</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.51%); opacity: 0.80\" title=\"-0.006\">preaches</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.59%); opacity: 0.80\" title=\"-0.006\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.60%); opacity: 0.81\" title=\"0.019\">pretenses</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.80%); opacity: 0.81\" title=\"0.009\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.15%); opacity: 0.82\" title=\"-0.033\">justify</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.58%); opacity: 0.88\" title=\"0.139\">harassing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.20%); opacity: 0.85\" title=\"0.082\">people</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.19%); opacity: 0.80\" title=\"-0.001\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.98%); opacity: 0.83\" title=\"-0.047\">criticizing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.40%); opacity: 0.85\" title=\"-0.081\">bland</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 90.41%); opacity: 0.83\" title=\"-0.044\">overused</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.99%); opacity: 0.80\" title=\"-0.008\">tropes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.32%); opacity: 0.84\" title=\"0.066\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.95%); opacity: 0.81\" title=\"-0.013\">like</span><span style=\"opacity: 0.80\">.</span>\n    </p>\n\n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n\n"},"metadata":{}}]},{"cell_type":"code","source":"show_html_expl(explain_prediction(clf, valid_texts.reset_index(drop=True)[1], vec, target_names=train_texts),\n               force_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T09:37:17.143446Z","iopub.execute_input":"2023-04-15T09:37:17.143745Z","iopub.status.idle":"2023-04-15T09:37:17.414664Z","shell.execute_reply.started":"2023-04-15T09:37:17.143705Z","shell.execute_reply":"2023-04-15T09:37:17.413713Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n\n\n    \n        <p>Explained as: linear model</p>\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n        \n\n    \n\n        \n            \n                \n                \n    \n        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n            <b>\n    \n        y=1\n    \n</b>\n\n    \n    (probability <b>0.545</b>, score <b>0.181</b>)\n\ntop features\n        </p>\n    \n    <table class=\"eli5-weights\"\n           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n        <thead>\n        <tr style=\"border: none;\">\n            \n                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n                    Contribution<sup>?</sup>\n                </th>\n            \n            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n            \n        </tr>\n        </thead>\n        <tbody>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 85.53%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.340\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        nerd\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 86.29%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.314\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        women\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 90.65%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.182\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        girls\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 91.47%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.160\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        real\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 92.25%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.139\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        harassing\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 92.60%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.130\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        tier\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 92.63%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.129\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        everything\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 93.99%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.097\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        counter\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 94.01%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.096\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        belittle\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 94.65%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.082\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        people\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 95.41%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.066\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        they\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 95.93%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.055\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        no\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 96.76%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.040\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        has\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 96.79%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.039\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        being\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 98.05%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.019\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        pretenses\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 98.12%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.018\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        to\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 98.22%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.017\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        tactics\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 98.25%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.017\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        label\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 98.52%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.013\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        the\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 99.03%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.007\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        lack\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.005\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        that\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 99.83%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.001\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        things\n    </td>\n    \n</tr>\n        \n        \n\n        \n        \n            <tr style=\"background-color: hsl(0, 100.00%, 99.52%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.003\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        for\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 99.13%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.006\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        are\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 99.10%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.006\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        preaches\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 98.91%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.008\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        tropes\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 98.83%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.009\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        then\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 98.57%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.012\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        kindergarten\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 98.36%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.015\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        movement\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 98.28%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.016\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        it\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 98.02%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.020\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        afterwards\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 97.86%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.022\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        of\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 97.62%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.026\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        like\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 97.16%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.033\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        justify\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 96.75%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.040\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        about\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 96.53%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.044\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        overused\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 96.37%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.047\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        criticizing\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 96.28%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.049\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        in\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 96.11%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.052\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        and\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 95.46%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.065\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        whine\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 94.72%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.081\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        bland\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 93.57%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.107\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        beyond\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 92.65%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.129\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        some\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 92.27%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.139\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        meaning\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 91.85%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.149\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        actually\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 91.12%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.169\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        interested\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.539\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        &lt;BIAS&gt;\n    </td>\n    \n</tr>\n        \n\n        </tbody>\n    </table>\n\n            \n        \n\n        \n    \n        \n        \n    \n        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n            <b>\n    \n        y=1\n    \n</b>\n\n    \n    (probability <b>0.545</b>, score <b>0.181</b>)\n\ntop features\n        </p>\n    \n    <table class=\"eli5-weights\"\n           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n        <thead>\n        <tr style=\"border: none;\">\n            \n                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n                    Contribution<sup>?</sup>\n                </th>\n            \n            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n            \n        </tr>\n        </thead>\n        <tbody>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +0.720\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        Highlighted in text (sum)\n    </td>\n    \n</tr>\n        \n        \n\n        \n        \n            <tr style=\"background-color: hsl(0, 100.00%, 83.66%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.539\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        &lt;BIAS&gt;\n    </td>\n    \n</tr>\n        \n\n        </tbody>\n    </table>\n\n    \n\n\n\n    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n        <span style=\"background-color: hsl(0, 100.00%, 95.24%); opacity: 0.81\" title=\"-0.016\">it</span><span style=\"opacity: 0.80\">&#x27;s </span><span style=\"background-color: hsl(0, 100.00%, 95.95%); opacity: 0.81\" title=\"-0.013\">like</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.72%); opacity: 0.80\" title=\"0.002\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.15%); opacity: 0.81\" title=\"0.017\">label</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.49%); opacity: 0.89\" title=\"-0.149\">actually</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.06%); opacity: 0.82\" title=\"0.040\">has</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.75%); opacity: 0.83\" title=\"0.055\">no</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.63%); opacity: 0.88\" title=\"-0.139\">meaning</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.22%); opacity: 0.86\" title=\"-0.107\">beyond</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.69%); opacity: 0.88\" title=\"-0.129\">some</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.05%); opacity: 0.81\" title=\"-0.012\">kindergarten</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 79.54%); opacity: 0.88\" title=\"0.130\">tier</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.08%); opacity: 0.81\" title=\"0.017\">tactics</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.80%); opacity: 0.81\" title=\"0.009\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.45%); opacity: 0.86\" title=\"0.096\">belittle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 62.12%); opacity: 0.99\" title=\"0.314\">women</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.19%); opacity: 0.80\" title=\"-0.001\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.13%); opacity: 0.82\" title=\"0.039\">being</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.46%); opacity: 0.90\" title=\"-0.169\">interested</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.72%); opacity: 0.83\" title=\"-0.049\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.53%); opacity: 0.80\" title=\"0.001\">things</span><span style=\"opacity: 0.80\">, (</span><span style=\"background-color: hsl(0, 100.00%, 93.39%); opacity: 0.82\" title=\"-0.026\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.78%); opacity: 0.81\" title=\"-0.009\">then</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.45%); opacity: 0.84\" title=\"-0.065\">whine</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.02%); opacity: 0.82\" title=\"-0.040\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.49%); opacity: 0.80\" title=\"0.007\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.32%); opacity: 0.80\" title=\"0.007\">lack</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.10%); opacity: 0.81\" title=\"-0.022\">of</span><span style=\"opacity: 0.80\"> &quot;</span><span style=\"background-color: hsl(120, 100.00%, 76.42%); opacity: 0.89\" title=\"0.160\">real</span><span style=\"opacity: 0.80\">&quot; </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.340\">nerd</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.17%); opacity: 0.91\" title=\"0.182\">girls</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.54%); opacity: 0.81\" title=\"-0.020\">afterwards</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(0, 100.00%, 93.39%); opacity: 0.82\" title=\"-0.026\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.72%); opacity: 0.80\" title=\"0.002\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.64%); opacity: 0.88\" title=\"0.129\">everything</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.49%); opacity: 0.80\" title=\"0.007\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.39%); opacity: 0.86\" title=\"0.097\">counter</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 95.48%); opacity: 0.81\" title=\"-0.015\">movement</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.51%); opacity: 0.80\" title=\"-0.006\">preaches</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.59%); opacity: 0.80\" title=\"-0.006\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.60%); opacity: 0.81\" title=\"0.019\">pretenses</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.80%); opacity: 0.81\" title=\"0.009\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.15%); opacity: 0.82\" title=\"-0.033\">justify</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.58%); opacity: 0.88\" title=\"0.139\">harassing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.20%); opacity: 0.85\" title=\"0.082\">people</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.19%); opacity: 0.80\" title=\"-0.001\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.98%); opacity: 0.83\" title=\"-0.047\">criticizing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.40%); opacity: 0.85\" title=\"-0.081\">bland</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 90.41%); opacity: 0.83\" title=\"-0.044\">overused</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.99%); opacity: 0.80\" title=\"-0.008\">tropes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.32%); opacity: 0.84\" title=\"0.066\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.95%); opacity: 0.81\" title=\"-0.013\">like</span><span style=\"opacity: 0.80\">.</span>\n    </p>\n\n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n\n"},"metadata":{}}]},{"cell_type":"code","source":"vec = TfidfVectorizer()\nlogreg = LogisticRegression(C=0.01)\npipeline_lr = Pipeline([('vec', vec), ('clf', logreg)])\npipeline_lr.fit(train_texts, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T09:44:11.820525Z","iopub.execute_input":"2023-04-15T09:44:11.820844Z","iopub.status.idle":"2023-04-15T09:44:28.431645Z","shell.execute_reply.started":"2023-04-15T09:44:11.820792Z","shell.execute_reply":"2023-04-15T09:44:28.430761Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"Pipeline(memory=None,\n     steps=[('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n ...penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False))])"},"metadata":{}}]},{"cell_type":"code","source":"predict = pipeline_lr.predict(valid_texts)\naccuracy_score(y_valid, predict)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T09:44:28.433173Z","iopub.execute_input":"2023-04-15T09:44:28.433453Z","iopub.status.idle":"2023-04-15T09:44:32.205400Z","shell.execute_reply.started":"2023-04-15T09:44:28.433405Z","shell.execute_reply":"2023-04-15T09:44:32.204326Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"0.6714405565624827"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}